\documentclass{report}
\usepackage[a4paper, total={17cm, 24cm}]{geometry}
\usepackage{amsmath}

\usepackage{hhline}
\usepackage{bm}
\usepackage{pgfplots}
\usepackage{amssymb}
\usepackage{algorithm}
\usepackage{algorithmicx}
\usepackage{algpseudocode}
\usepackage{color, soul}
\usepackage[backend=biber]{biblatex}
\addbibresource{references.bib}
\graphicspath{{imgs/}}


%opening
\title{Domain Adaptation}
\author{Ash}

\def\BState{\State\hskip-\ALG@thistlm}

\newcommand{\TODO}[1]{\sethlcolor{pink}\hl{\\(#1)\\}}
\newcommand{\FEEDBACK}[1]{\sethlcolor{green}\hl{\\ Feedback: \\#1\\}}
\newcommand{\TOCITE}[2][citation needed]{\textsuperscript{\underline{#1}}}
\newcommand\ddfrac[2]{\frac{\displaystyle #1}{\displaystyle #2}}
\newcommand{\quoteit}[1]{\begin{quote}\textit{#1}\end{quote}}

\begin{document}
	
\chapter*{Domain Adaptation}

\quoteit{Domain Adaptation (DA) allows machine learning methods trained on data sampled from one distribution to be applied to data sampled from another.}
\vspace{3cm}


\subsubsection*{One-Step DA}
The source and target domains are directly related, allowing for knowledge transfer in one step.

\subsubsection*{Multi-Step DA}
Build a series of intermediate bridges to connect two seemingly unrelated domains, then perform one-step DA via this bridge.



\setcounter{chapter}{1}
\chapter*{One-Step Domain Adaptation}
One-step domain adaptation can be categorised into three approaches, each of which can be further split into subcategories as shown in table I.
\begin{figure}[!h]
	\centering
	\includegraphics[width=17cm]{one-step-approaches}
	\label{fig:one-step-approaches:1}
\end{figure}






\section{Discrepancy-Based DA}
\quoteit{Assumes that fine-tuning the deep network model with labelled or unlabelled target data can diminish the shift between the two domains.}

\subsection{Class Criterion}
\quoteit{Uses the class label information as a guide for transferring knowledge between different domains. When such samples are unavailable, some other techniques can be adopted to substitute for class labelled data, such as pseudo labels and attribute representation.}

\subsubsection{Soft Label Loss}
Introduced by Geoff Hinton (of course), a ``soft'' softmax can be used when training on the new domain as shown in equation \ref{eqn:softmax:1}, where $T$ is the temperature that's normally set to 1 in standard softmax. Larger values of $T$ produce a softer probability distribution over classes.
\begin{align}
	q_{i} = \ddfrac{exp(z_{j}/T)}{\sum\nolimits_{j} exp(z_{j}/T)} \label{eqn:softmax:1}
\end{align}
Originally used in a paper about distilling knowledge in other networks, using soft labels rather than hard labels can preserve relationships between classes across domains. It is recommended that this is used in conjunction with the domain confusion loss (discussed later). \\ \par

From \parencite{simultaneousdeeptransfer}:
\quoteit{The bottle soft label will have a higher weight on mug than on keyboard, since bottles and mugs are more visually similar. Thus, soft label training with this particular soft label directly enforces the relationship that bottles and mugs should be closer in feature space than bottles and keyboards.}
\quoteit{... we ensure that the parameters for categories without any labelled target data are still updated to output non-zero probabilities.}

\subsubsection{Embedded Metric Learning}
\textit{Unified Deep Supervised Domain Adaptation and Generalization}\parencite{unifieddeepadaptation} uses a siamese network to process source and target domain examples simultaneously, and applies a \textit{Contrastive Semantic Alignment Loss} to the embedded examples, minimising the dissimilarity across domains. \\ \\
\textit{Deep Transfer Metric Learning}\parencite{deeptransfermetric} demonstrates an unsupervised technique for transforming samples into a new subspace. Their training objectives are that:
\begin{enumerate}
	\item the inter-class variations are maximised and the intra-class variations are minimised.
	\item the distribution divergence between the source domain and the target domain at the top layer of the network is minimised.
\end{enumerate}






\subsection{Statistic Criterion}
\quoteit{Aligns the statistical distribution shift between the source and target domains using some mechanisms.}
A frequently used metric is \textbf{Maximum Mean Discrepancy (MMD)}, which estimates the distance between different distributions.  \\ \\

\textit{Deep Domain Confusion: Maximizing for Domain Invariance}\parencite{deepdomainconfusion} applies an \textit{adaptation layer} (bottleneck) at some point in the network, then jointly minimises classification error while maximising MMD at the adaptation layer. The minimisation of MMD between source and target domains is known as \textbf{domain confusion}.
\begin{figure}[h]
	\centering
	\includegraphics[width=10cm]{domainconfusion}
	\caption{By jointly minimising classification error while maximising domain confusion, we learn representations that are discriminative and domain invariant}
	\label{fig:domainconfusion}
\end{figure}
\begin{figure}[h]
	\centering
	\includegraphics[width=6cm]{imgs/domainconfusion2}
	\caption{Architecture of Deep Domain Confusion\parencite{deepdomainconfusion}}
	\label{fig:domainconfusion2}
\end{figure}
\textit{Learning Transferable Features with Deep Adaptation Networks}\parencite{learningtransferabledeepadaptation} takes it one step further by applying domain confusion to several layers of a network. \\

\begin{figure}[h]
	\centering
	\includegraphics[width=10cm]{imgs/deepcoral}
	\caption{Deep CORAL architecture\parencite{deepcoral}}
	\label{fig:deepcoral}
\end{figure}
\textit{Deep CORAL}\parencite{deepcoral} is similar to the previous systems, but instead of minimising MMD, minimises the difference in second-order statistics between the source and target
feature activations (the learned feature covariances). Similarly, this can be applied to any layer of a network.






\subsection{Architecture Criterion}
\quoteit{Aims at improving the ability of learning more transferable features by adjusting the architectures of deep networks. The techniques that are proven to be cost effective include adaptive batch normalisation (BN), weak-related weight and domain-guided dropout.}

Instead of transfer-learning by fine-tuning weights to a target domain, \textit{Beyond Sharing Weights for Deep Domain Adaptation}\parencite{beyondsharing} adopts a dual-stream network architecture where select layers in the target classifier has distinct weights, which are regularised such that they have a similar distribution as those in the source domain model. They also say \textit{``...the class-related knowledge is stored in the weight matrix, whereas domain-related knowledge is represented by the statistics of the batch normalization (BN) layer''} \\
\begin{figure}
	\centering
	\includegraphics[width=7cm]{imgs/beyondsharing}
	\caption{}
	\label{fig:beyondsharing}
\end{figure}

\textit{Revisiting Batch Normalization For Practical Domain Adaptation}\parencite{revisitingbatchnorm} hypothesizes that ``the label related knowledge is stored in the weight matrix of each layer, whereas domain related knowledge is represented by the statistics of the Batch Normalization layer''. They  recommend the usage of \textbf{Adaptive Batch Normalization} to normalise features between domains. \\

\textit{AutoDIAL: Automatic DomaIn Alignment Layers}\parencite{autodial} feeds source/target domain images into a network in parallel and inserts \textbf{Domain Alignment (DA) layers} (similar to batch norm) to enforce feature similarity across domains. A learned parameter controls this ``degree of domain alignment'' as features pass through each of the DA layers. \\

The survey\parencite{deepdomainsurvey} states that \textit{Improved Texture Networks}\parencite{texturenets} shows \textbf{Instance Normalisation} performs better at DA than standard Batch Normalisation... but I couldn't find that in the paper. \\

\textit{Learning Deep Feature Representations with Domain Guided Dropout for
	Person Re-identification}\parencite{domainguideddropout} introduces \textbf{Domain Guided Dropout}, which is essentially a method of applying dropout to irrelevant/unhelpful neurons per-domain. It's used like so:
\begin{enumerate}
	\item Train on all domains
	\item For each entry in a feature vector for an image:
	\item The impact score of this neuron is $\mathcal{L}(g(x)_{\setminus i})-\mathcal{L}(g(x))$, where $g(x)_{\setminus i}$ is the feature vector after zeroing-out the $i$-th neuron response to zero, averaged over all images in each domain
	\item Continue training, but use the scores to guide dropout for each domain
\end{enumerate}
This comes in two flavours: deterministic and stochastic. Deterministic applies the resultant mask when the score is $<0$, stochastic uses the score to sample from a Bernoulli distribution.

\subsection{Geometric Criterion}
\quoteit{Bridges the source and target domains according to their geometrical properties. This criterion assumes that the relationship of geometric structures can reduce the domain shift.}



\section{Adversarial-Based DA}

\subsection{Generative Models}
\quoteit{The typical case is to use source images, noise vectors or both to generate simulated samples that are similar to the target samples and preserve the annotation information of the source domain}
\textit{Cross-Domain Weakly-Supervised Object Detection through Progressive Domain Adaptation}\parencite{crossdomainweakly} uses two techniques to generate target domain examples. Perform image-to-image translation from the source to target domain using CycleGAN $=$ accurate bounding boxes, inaccurate visual features. Perform object detection to build ``pseudo-labels'' $=$ inaccurate bounding boxes, accurate visual features.
\begin{figure}
	\centering
	\includegraphics[width=10cm]{imgs/crossdomainweakly}
	\caption{A three-step training approach to go from source to target images. DT = Domain Transfer GAN; PL = Pseudo-Labels (from detector)}
	\label{fig:crossdomainweakly}
\end{figure}

\subsection{Non-Generative Models}
\quoteit{The feature extractor learns a discriminative representation using the labels in the source domain and maps the target data to the same space through a domain-confusion loss.}

\textit{Domain Adaptive Faster R-CNN for Object Detection in the Wild}\parencite{adaptrcnn} adds an \textbf{Image-Level Domain Classifier} which is trained to predict the domain from which an image is sampled. They reverse gradients at the boundary, to apply adversarial training.
\begin{figure}[h!]
	\centering
	\includegraphics[width=14cm]{imgs/adaptrcnn}
	\caption{(a): Faster R-CNN; (b, upper): a Faster R-CNN-specific DA solution; (b, lower): conv-net used to predict image domain, with gradient-reversal-layer (GRL) at the boundary}
	\label{fig:adaptrcnn}
\end{figure}




\section{Reconstruction-Based DA}

\quoteit{Assumes that the data reconstruction of the source or target samples can be helpful for improving the performance of DA}

\subsection{Encoder-Decoder Reconstruction}
\quoteit{By using stacked autoencoders (SAEs), encoder-decoder reconstruction methods combine the encoder network for representation learning with a decoder network for data reconstruction}

\subsection{Adversarial Reconstruction}
\quoteit{The reconstruction error is measured as the difference between the reconstructed and original images within each image domain by a cyclic mapping obtained via a GAN discriminator}





\setcounter{chapter}{2}
\chapter*{Multi-Step Domain Adaptation}
Multi-step domain adaptation can be categorised into three approaches as shown in table II.
\begin{figure}[!h]
	\centering
	\includegraphics[width=14cm]{two-step-approaches}
	\label{fig:two-step-approaches:1}
\end{figure}
\subsection{Hand-Crafted}
\quoteit{Users determine the intermediate domains based on experience.}
\subsection{Instance-Based}
\quoteit{Selecting certain parts of data from the auxiliary datasets to compose the intermediate domains to train the deep network}
\subsection{Representation-Based}
\quoteit{Transfer is enabled via freezing the previously trained network and using their intermediate representations as input to the new one.}


\chapter*{Application to Swimming Project}

	
\end{document}


